\documentclass[a4paper,10pt]{scrartcl}
\usepackage[utf8]{inputenc}
\usepackage{amsmath,latexsym}
\usepackage[margin=3cm]{geometry}
\usepackage{axodraw2}
\usepackage{listings}
\lstset{basicstyle=\ttfamily,
keywordstyle=\color{magenta},
  showstringspaces=false
}

\renewcommand{\baselinestretch}{1.5}

\title{Documentation of GPT for QPDFs \newline Part I: General Information about GPT}
\author{Philipp Scior}
\date{\today}
\newcommand{\tr}{\text{Tr\,}}
\newcommand{\bs}{\boldsymbol}

\begin{document}
\maketitle
This is part I of the documentation. Contents will be installation of Grid, GPT, informations about implementing a fast algorithm in Grid and interfacing that
for using it in GPT as well as general introduction to computing correlators in GPT.

\section{Installation}
This project uses Grid and the Grid Python Toolkit (GPT). The easiest way to get all components running is to download GPT first by running:
\begin{lstlisting}[language=bash]
    git clone https://github.com/philomat/gpt.git
\end{lstlisting}
This is a fork of Christoph Lehner's upstream version, with some custom functionalities, e.g. Coulomb gauge smearing and improved contractions. The upstream
version can be found at https://github.com/lehner/gpt.git
Installation is done by going to 
\begin{lstlisting}[language=bash]
    cd gpt/scripts/bootstrap/
\end{lstlisting}
and exectuing one of the installation script. There are scripts for several modern clusters, e.g. JUWELS Booster.
This downloads Lime, Grid and some other dependecies of GPT and Grid and compiles and installs them. \newline
\textbf{Note:}
\begin{itemize}
    \item Some of our custom functionalities need a custom Grid library, get it at https://github.com/philomat/grid.git (you might have to change the GPT install
    scripts to download this version instead of the upstream version.)
    \item GPT itself already uses a custom version of Grid (https://github.com/lehner/Grid.git). Our custom Grid is a fork of Christoph's
    \item Peter Boyle's upstream version of Grid can be found at https://github.com/paboyle/Grid.git
    \item Grid also requires the GNU Multiple Precision Arithmetic Library (GMP). This is not included in the bootstrapping script and might have to be 
    installed by the user.
\end{itemize}
The intallations script will start downloading all necessary prerequisites for Grid and will start compiling Grid. Ofter compiling Grid into a static library
the script will compile CGPT (C++ code that implements the interface between Python and Grid\footnote{Actually, some fast algorithms are implemented in CGPT
without ever using Grid functionalites.}). \newline
We have successfully installed Grid and CGPT, now we need to tell the Python interpreter where to find CGPT. So, either execute:
\begin{lstlisting}[language=bash]
    source path_to_gpt/lib/cgpt/build/source.sh
\end{lstlisting}
in all of your submit scripts, or include it in your bashrc/zshrc.
Congratulations, we are now able to use GPT.\newline
\textbf{Note:}
\begin{itemize}
    \item Grid is compiled into a static library. Therefore, if one ever modifies Grid or if one gets a new upstream version recompilation of
    Grid and CGPT is necessary.
    \item Changes to CGPT will also require recompiling CGPT. Use path\_to\_gpt/lib/cgpt/make.qcdonly to recompile.
\end{itemize}

\section{Implementing an interface to a Grid function}
In principle, most functions functionalities from Grid can already be used in GPT. However, not all Grid functions posses an interface to GPT.
Here, I will give and example of how to write an Interface to Grid so the reader should be able to repeat the necessary steps for his own function, if needed.
The example will be reunitarization of a SU(3) gauge field, either for APE or HYP smearing. Let us start from the callable 
python function and move down to the function calling the function implemented in Grid.\\
Start by adding a function to a suitable .py file, e.g. to path\_to\_gpt/lib/gpt/core.transform.py:
\begin{lstlisting}[language=python]
def projectSU3(first, second):
    if(type(first)==gpt.lattice and type(second)==gpt.lattice):
        l = gpt.eval(first)
        m = gpt.eval(second)
    else:
        print("Type error in projectSU3")
    for i in l.otype.v_idx:
        cgpt.ProjectSU3(l.v_obj[i], m.v_obj[i])
\end{lstlisting}
For the function to be actually be callable in another python file, we have to add the functions name to the \_\_init\_\_.py file in the same folder under
\begin{lstlisting}[language=python]
from gpt.core.transform import (
    projectSU3,
    ...
)
\end{lstlisting}
Now, we have to define a CGPT function with the name ProjectSU3. For that either add a new file e.g. unitarization.cc to the path path\_to\_gpt/lib/cgpt/lib/
or add the function to a suitable existing file in said directory. \textbf{CAVE: If you add functions to files in this folder you might get errors when 
compiling or executing, even if the code is correct. To avoid this, add all new functions at the end of the respective files or classes in the files.} 
In this example we choose to add the new file unitarization.cc with content:
\begin{lstlisting}[language=C++]
#include "lib.h"

EXPORT(ProjectSU3,{

    void* _in;
    void* _out;
    if (!PyArg_ParseTuple(args, "ll", &_in, &_out)) {
      std::cout << "C code: problems parsing arguments" << std::endl;
      return NULL;
    }

    cgpt_Lattice_base* in = (cgpt_Lattice_base*)_in;
    cgpt_Lattice_base* out = (cgpt_Lattice_base*)_out;

    auto& In = compatible<iColourMatrix<vComplexD>>(in)->l;
    auto& Out = compatible<iColourMatrix<vComplexD>>(out)->l;
    
    Projectnew(In,Out);



    return PyLong_FromLong(0);    

});

\end{lstlisting}
All necessary includes happen in lib.h. We define the function ProjectSU3 to have two arguments, which are the input lattice and the output lattice. We then cast the arguments,
initially being void pointers, to lattice base class pointers and execute the Grid function Projectnew(In, Out). Next we have to define and implement the new Grid function Projectnew(In,Out).
This is done in the file path\_to\_gpt/dependecies/Grid/Grid/qcd/utilsSUn.h and I will not repeat the algorithm here. The algorithm is taken from CHROMA \\
Now we have defined everything, first recompile Grid, then to compile the new CGPT functionalities just execute
\begin{lstlisting}[language=bash]
    cd path_to_gpt/lib/cgpt
    ./make.qcdonly
\end{lstlisting}
again and the gpt function projectSU3 is ready to use. Just note that, like most of the other GPT functions, projectSU3 does not operate on the whole
gauge field but on the individual four-vector components, i.e. to unitarize the gauge field call
\begin{lstlisting}[language=python]
import gpt as g
for mu in range(len(U)):
    g.projectSU3(U[mu])
\end{lstlisting}

\section{Measuring Correlators using GPT}
In this section I will describe how to measure the correlator for the determination of e.g. the pion mass.
\begin{lstlisting}[language=python]
    import gpt as g
    import numpy as np

    U = g.load("gauge.file")

    U_hyp = g.qcd.gauge.smear.hyp(U, alpha = np.array([0.75, 0.6, 0.3]))
    plaq_hyp = g.qcd.gauge.plaquette(U_hyp)
    
    g.message(f"HYP smeared Plaquette = {plaq_hyp}")
    
    grid = U_hyp[0].grid
    
    p = {
        "kappa" : 0.12623,
        "csw_r": 1.0372,
        "csw_t": 1.0372,
        "xi_0": 1,
        "nu": 1,
        "isAnisotropic": False,
        "boundary_phases": [1, 1, 1, -1],
    }
    
    w = g.qcd.fermion.wilson_clover(U_hyp, p)
    
    # create point source
    src = g.mspincolor(grid)
    g.create.point(src, [1, 0, 0, 0])
    
    # build solver using eo prec. and cg
    inv = g.algorithms.inverter
    pc = g.qcd.fermion.preconditioner
    cg = inv.cg({"eps": 1e-6, "maxiter": 10000})

    slv = w.propagator(inv.preconditioned(pc.eo2_ne(), cg))
 
    # propagator
    dst = g.mspincolor(grid)
    dst @= slv * src
    
    # pi-pi corr:
    corr_pion = g.slice(g.trace(g.adj(dst) * dst), 3)  

\end{lstlisting}
We need to include numpy and gpt. First, we need to load the gauge field and we do one level of HYP smearing with the std. HYP parameters.
Next we print the plaquette of the HYP smeared field, to stdout. Now we set the parameters for a Wilson-Clover Dirac operator. The
values for $\kappa$ and $c_{SW}$ are taken from the QLUA production code. With the HYP smeared field and the parameter set we are now
able to make and instance of a Wilson-Clover Dirac operator. Next we set up a preconditioner and a cg inverter and use those to set up
a solver using a CG inverter and the even-odd preconditioned Dirac operator. The solver is then applied to a point source (The point 
source is located at an odd point, this is needed to make use of the eo preconditioner) yielding the propagator we need to compute our
$\pi \, \pi$ and $A_4 \, \pi$ correlation functions. \newline
\subsection{Inverters}
There are several different inverters implemented in GPT. So far I tried the following:
\paragraph{EO Preconditiond CG}
Using the even-odd preconditioner basically does an LDU decomposition of the Dirac operator in "even-odd" space. You can then show
that instead of inverting D you get away with inverting the two sub-matrices: $D_{oo}$ and $N = 1 - D_{ee}^{-1} D_{eo} D_{oo}^{-1} D_{oe}$.
These have only have the number of rows and columns as D so this is more efficient than inverting D. Further, we use the old 
$N^{-1} = (N^\dagger N)^{-1} N^{dagger}$ trick and get away with using a std. CG inverter instead of BiCGStab. Inverting $D_{oo}$ is easy
as it is diagonal in coordinate space and hermitian. In fact, without a clover term it is diagonal.
\paragraph{Multi-Grid}
I got a 2-lvl and a 3-lvl MG inverter working. For a $64^4$ lattice with physical mass Wilson quarks the simple eo preconditioned CG was more
efficient tough. This is not yet optimized in the same way as the QUDA MG inverters.
\paragraph{Deflated Solvers}
Deflation is also possible and works well.



\end{document}